# -*- coding: utf-8 -*-
"""Zero-Shot and One-Shot and Few-Shot Learning Using LLMs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zzUahsssagK-XZ9Ql8wTu8hCmhz-sMeI
"""

!pip install datasets

from datasets import load_dataset
from transformers import AutoModelForSeq2SeqLM
from transformers import AutoTokenizer
from transformers import GenerationConfig

hugginface_dataset_name = "knkarthick/dialogsum"
dataset = load_dataset(hugginface_dataset_name)

dataset

dataset['train'][5]['dialogue']

print(dataset['train'][5]['dialogue'])

print(f"Human summary: {dataset['train'][5]['summary']}")

model_name = "google/flan-t5-base"
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)

sentence ="What time is it, Tom?"

sentence_encoded = tokenizer(sentence, return_tensors='pt')

print(sentence_encoded)

sentence_decoded = tokenizer.decode(
    sentence_encoded["input_ids"][0],
    skip_special_tokens=True
)

print(sentence_decoded)

print("Encoded:")
print(sentence_encoded["input_ids"][0])
print("---------------------------------------------------")
print("Decoded:")
print(sentence_decoded)

"""# sample code for ZERO SHOT"""

model_name = 'facebook/mbart-large-50-many-to-many-mmt'
 model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
 tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
 tokenizer.tgt_lang = "fa_IR"

 prompt = f"""
  Summarize the following Persian text in Persian:
آموزش رانندگی فرآیندی مرحله‌به‌مرحله است که با آشنایی با قوانین راهنمایی و رانندگی و تابلوهای راه آغاز می‌شود و سپس به یادگیری مهارت‌های عملی نظیر کنترل فرمان، استفاده صحیح از پدال‌ها، رعایت فاصله ایمن، استفاده از آینه‌ها، دنده‌کشی و پارک کردن در شرایط مختلف می‌پردازد؛ در این مسیر، هنرجو باید توانایی تشخیص موقعیت‌های خطرناک، تصمیم‌گیری سریع و رعایت ادب و احترام در رانندگی را کسب کند و با تمرین مستمر تحت نظر مربی مجرب، آمادگی لازم برای شرکت در آزمون‌های آیین‌نامه و عملی را پیدا کند تا در نهایت بتواند به‌عنوان یک راننده مسئول، ایمن و قانون‌مدار در جاده‌ها تردد کند.


 """

model.config.forced_bos_token_id = tokenizer.lang_code_to_id["fa_IR"]

inputs = tokenizer(prompt, return_tensors = 'pt')
output = tokenizer.decode(
    model.generate(
        inputs["input_ids"],
        max_new_tokens=50,
    )[0],
    skip_special_tokens=True
)

print(f'MODEL GENERATION - ZERO SHOT:{output}')

"""# sample code for ZERO SHOT"""

model_name = "google/flan-t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

example_indices = [20,40]

for i, index in enumerate(example_indices):
  dialogue = dataset['test'][index]['dialogue']
  summary = dataset['test'][index]['summary']

  # Sample Prompt
  prompt = f"""

Summurize the following conversation

  {dialogue}

Summary:

  """

  inputs = tokenizer(prompt, return_tensors='pt')

  output = tokenizer.decode(
    model.generate(
        inputs["input_ids"],
        max_new_tokens=50,
    )[0],
    skip_special_tokens=True
  )

  print("---------------------------------------------")
  print('Example', i + 1)
  print(f'INPUT PROMPT: {prompt}')
  print("---------------------------------------------")
  print(f'Human Base Summray: {summary}')
  print("---------------------------------------------")
  print(f'*** Model Generation - Zero - Shot: {output}')

"""# sample code for ZERO SHOT"""

for i, index in enumerate(example_indices):
  dialogue = dataset['test'][index]['dialogue']
  summary = dataset['test'][index]['summary']

# Sample Prompt
  prompt = f"""

Dialogue :

  {dialogue}

What was going on?

  """
  inputs = tokenizer(prompt, return_tensors='pt')

  output = tokenizer.decode(
    model.generate(
        inputs["input_ids"],
        max_new_tokens=50,
    )[0],
    skip_special_tokens=True
  )

  print("---------------------------------------------")
  print('Example', i + 1)
  print(f'INPUT PROMPT: {prompt}')
  print("---------------------------------------------")
  print(f'Human Base Summray: {summary}')
  print("---------------------------------------------")
  print(f'*** Model Generation - Zero - Shot: {output}')

"""# Defind Prompt Function"""

def sample_prompt(sample_indices, sample_index_to_summarize):
  prompt = ''
  for index in sample_indices:
    dialogue = dataset['test'][index]['dialogue']
    summary = dataset['test'][index]['summary']

    prompt = f"""

    Dialogue :

      {dialogue}

    What was going on?
    {summary}
      """
  dialogue = dataset['test'][sample_index_to_summarize]['dialogue']

  prompt += f"""

  Dialogue :

    {dialogue}

  What was going on?

    """

  return prompt

"""# sample code for ONE SHOT"""

sample_indices=[22]
sample_index_to_summarize = 200

one_shot_prompt = sample_prompt(sample_indices, sample_index_to_summarize)

print(one_shot_prompt)

sample_indices=[22]
sample_index_to_summarize = 200

summary = dataset['test'][sample_index_to_summarize]['summary']

one_shot_prompt = sample_prompt(sample_indices, sample_index_to_summarize)

inputs = tokenizer(one_shot_prompt, return_tensors='pt')

output = tokenizer.decode(
  model.generate(
      inputs["input_ids"],
      max_new_tokens=50,
  )[0],
  skip_special_tokens=True
)


print("---------------------------------------------")
print(f'Human Base Summray: {summary}')
print("---------------------------------------------")
print(f'*** Model Generation - ONE - Shot: {output}')

"""# Sample code for FEW SHOT"""

sample_indices=[200, 60 ,150]
sample_index_to_summarize = 200

few_shot_prompt = sample_prompt(sample_indices, sample_index_to_summarize)

print(few_shot_prompt)

sample_indices=[200, 60,150]
sample_index_to_summarize = 200

summary = dataset['test'][sample_index_to_summarize]['summary']

few_shot_prompt = sample_prompt(sample_indices, sample_index_to_summarize)

inputs = tokenizer(few_shot_prompt, return_tensors='pt')

output = tokenizer.decode(
  model.generate(
      inputs["input_ids"],
      max_new_tokens=50,
  )[0],
  skip_special_tokens=True
)


print("---------------------------------------------")
print(f'Human Base Summray: {summary}')
print("---------------------------------------------")
print(f'*** Model Generation - FEW - Shot: {output}')